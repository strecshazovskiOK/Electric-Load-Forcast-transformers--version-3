{
    "sourceFile": "models/architectures/transformers/resolution_specific/monthly_transformer.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1733172086006,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1733172190831,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,9 @@\n import torch\r\n from torch import nn, Tensor\r\n import math\r\n \r\n-from ....data_loading.base.interval_types import TimeInterval\r\n+from data_loading.types.interval_types import TimeInterval\r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n from ....registry.factory import ModelFactory\r\n from ....registry.model_types import ModelType\r\n from ....components.layers import EncoderLayer, DecoderLayer\r\n"
                },
                {
                    "date": 1733172734377,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,286 @@\n+from typing import Dict, Any, Optional\r\n+from datetime import datetime\r\n+import pandas as pd\r\n+import torch\r\n+from torch import nn, Tensor\r\n+import math\r\n+\r\n+from data_loading.types.interval_types import TimeInterval\r\n+from .base_resolution_transformer import BaseResolutionTransformer\r\n+from ....registry.factory import ModelFactory\r\n+from ....registry.model_types import ModelType\r\n+from ....components.layers import EncoderLayer, DecoderLayer\r\n+\r\n+@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\n+class MonthlyTransformer(BaseResolutionTransformer):\r\n+    \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n+\r\n+    def __init__(self, config: Dict[str, Any]):\r\n+        # Validate resolution\r\n+        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n+            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n+        \r\n+        super().__init__(config)\r\n+        \r\n+        # Monthly-specific configurations\r\n+        self.seasonal_features = self.d_model // 2\r\n+        self.yearly_features = self.d_model // 2\r\n+        \r\n+        # Setup specialized components\r\n+        self._setup_seasonal_components()\r\n+        self._setup_yearly_components()\r\n+        self._setup_trend_components()\r\n+\r\n+    def _setup_seasonal_components(self) -> None:\r\n+        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n+        # Seasonal embeddings\r\n+        self.season_embedding = nn.Embedding(4, self.d_model)\r\n+        self.month_embedding = nn.Embedding(12, self.d_model)\r\n+        \r\n+        # Seasonal pattern recognition\r\n+        self.seasonal_layer = nn.Sequential(\r\n+            nn.Linear(self.d_model, self.seasonal_features),\r\n+            nn.LayerNorm(self.seasonal_features),\r\n+            nn.GELU(),\r\n+            nn.Linear(self.seasonal_features, self.d_model),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+        \r\n+        # Seasonal attention\r\n+        self.seasonal_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+\r\n+    def _setup_yearly_components(self) -> None:\r\n+        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n+        # Yearly cycle embedding\r\n+        self.yearly_embedding = nn.Parameter(\r\n+            torch.randn(12, self.d_model)  # One embedding per month\r\n+        )\r\n+        \r\n+        # Yearly pattern recognition\r\n+        self.yearly_layer = nn.Sequential(\r\n+            nn.Linear(self.d_model, self.yearly_features),\r\n+            nn.LayerNorm(self.yearly_features),\r\n+            nn.GELU(),\r\n+            nn.Linear(self.yearly_features, self.d_model),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+        \r\n+        # Year-over-year attention\r\n+        self.yearly_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+\r\n+    def _setup_trend_components(self) -> None:\r\n+        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n+        # Long-term trend analysis\r\n+        self.trend_lstm = nn.LSTM(\r\n+            input_size=self.d_model,\r\n+            hidden_size=self.d_model,\r\n+            num_layers=2,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+        \r\n+        # Trend attention mechanism\r\n+        self.trend_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+        \r\n+        # Deseasonalization layer\r\n+        self.deseasonalization = nn.Sequential(\r\n+            nn.Linear(self.d_model * 2, self.d_model),\r\n+            nn.LayerNorm(self.d_model),\r\n+            nn.GELU(),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+\r\n+    def _create_encoder_layers(self) -> nn.ModuleList:\r\n+        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n+        return nn.ModuleList([\r\n+            EncoderLayer(\r\n+                d_model=self.d_model,\r\n+                n_heads=self.n_heads,\r\n+                d_ff=self.d_ff,\r\n+                dropout=self.dropout,\r\n+                attention_type=\"standard\",\r\n+                activation=\"gelu\"\r\n+            ) for _ in range(self.n_encoder_layers)\r\n+        ])\r\n+\r\n+    def _create_decoder_layers(self) -> nn.ModuleList:\r\n+        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n+        return nn.ModuleList([\r\n+            DecoderLayer(\r\n+                d_model=self.d_model,\r\n+                n_heads=self.n_heads,\r\n+                d_ff=self.d_ff,\r\n+                dropout=self.dropout,\r\n+                attention_type=\"standard\",\r\n+                activation=\"gelu\"\r\n+            ) for _ in range(self.n_decoder_layers)\r\n+        ])\r\n+\r\n+    def _extract_seasonal_patterns(\r\n+        self,\r\n+        x: Tensor,\r\n+        timestamps: torch.Tensor\r\n+    ) -> Tensor:\r\n+        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n+        # Convert tensor timestamps to pandas datetime\r\n+        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n+        \r\n+        # Get seasonal embeddings\r\n+        season_idx = torch.tensor((dates.month.values - 1) // 3, device=timestamps.device)\r\n+        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n+        \r\n+        seasonal_emb = self.season_embedding(season_idx)\r\n+        month_emb = self.month_embedding(month_idx)\r\n+        \r\n+        # Combine embeddings\r\n+        combined_emb = seasonal_emb + month_emb\r\n+        \r\n+        # Extract seasonal patterns\r\n+        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n+        \r\n+        # Apply seasonal attention\r\n+        seasonal_attn, _ = self.seasonal_attention(\r\n+            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n+        )\r\n+        \r\n+        return seasonal_attn\r\n+\r\n+    def _extract_yearly_patterns(\r\n+        self,\r\n+        x: Tensor,\r\n+        timestamps: Tensor\r\n+    ) -> Tensor:\r\n+        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n+        batch_size, seq_len = x.shape[:2]\r\n+        \r\n+        # Convert tensor timestamps to pandas datetime\r\n+        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n+        \r\n+        # Get yearly embeddings for each timestamp\r\n+        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n+        yearly_emb = self.yearly_embedding[month_idx]\r\n+        \r\n+        # Extract yearly patterns\r\n+        yearly_patterns = self.yearly_layer(yearly_emb)\r\n+        \r\n+        # Apply year-over-year attention\r\n+        yearly_attn, _ = self.yearly_attention(\r\n+            yearly_patterns, yearly_patterns, yearly_patterns\r\n+        )\r\n+        \r\n+        return yearly_attn\r\n+\r\n+    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n+        \"\"\"Analyze long-term trends.\"\"\"\r\n+        # Apply LSTM for trend analysis\r\n+        trend_output, _ = self.trend_lstm(x)\r\n+        \r\n+        # Apply trend attention\r\n+        trend_attn, _ = self.trend_attention(\r\n+            trend_output, trend_output, trend_output\r\n+        )\r\n+        \r\n+        return trend_attn\r\n+\r\n+    def encode(\r\n+        self,\r\n+        src: Tensor,\r\n+        src_mask: Optional[Tensor] = None,\r\n+        src_key_padding_mask: Optional[Tensor] = None,\r\n+        timestamps: Optional[Tensor] = None\r\n+    ) -> Tensor:\r\n+        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n+        # Standard embedding\r\n+        src = self.encoder_embedding(src)\r\n+        \r\n+        if timestamps is not None:\r\n+            # Extract patterns\r\n+            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n+            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n+            trend = self._analyze_trend(src)\r\n+            \r\n+            # Combine patterns\r\n+            src = src + seasonal_patterns + yearly_patterns + trend\r\n+            \r\n+            # Deseasonalize for trend analysis\r\n+            deseasonalized = self.deseasonalization(\r\n+                torch.cat([src, trend], dim=-1)\r\n+            )\r\n+            src = src + deseasonalized\r\n+        \r\n+        # Pass through encoder layers\r\n+        for layer in self.encoder_layers:\r\n+            src = layer(\r\n+                src,\r\n+                src_mask=src_mask,\r\n+                src_key_padding_mask=src_key_padding_mask\r\n+            )\r\n+        return src\r\n+\r\n+    def _adjust_attention_for_resolution(\r\n+        self,\r\n+        attention_weights: Tensor,\r\n+        resolution_minutes: int\r\n+    ) -> Tensor:\r\n+        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n+        seq_len = attention_weights.size(-1)\r\n+        \r\n+        # Seasonal pattern emphasis\r\n+        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n+        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n+        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n+        \r\n+        # Year transition emphasis\r\n+        is_year_end = (months == 11).float()\r\n+        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n+        \r\n+        return attention_weights\r\n+\r\n+    @classmethod\r\n+    def get_resolution_type(cls) -> TimeInterval:\r\n+        \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n+        return TimeInterval.MONTHLY\r\n+\r\n+    def forward(\r\n+        self,\r\n+        src: Tensor,\r\n+        tgt: Tensor,\r\n+        src_mask: Optional[Tensor] = None,\r\n+        tgt_mask: Optional[Tensor] = None,\r\n+        src_key_padding_mask: Optional[Tensor] = None,\r\n+        tgt_key_padding_mask: Optional[Tensor] = None,\r\n+        timestamps: Optional[Tensor] = None\r\n+    ) -> Tensor:\r\n+        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n+        memory = self.encode(\r\n+            src,\r\n+            src_mask=src_mask,\r\n+            src_key_padding_mask=src_key_padding_mask,\r\n+            timestamps=timestamps\r\n+        )\r\n+        \r\n+        output = self.decode(\r\n+            tgt,\r\n+            memory,\r\n+            tgt_mask=tgt_mask,\r\n+            memory_mask=None,\r\n+            tgt_key_padding_mask=tgt_key_padding_mask,\r\n+            memory_key_padding_mask=src_key_padding_mask\r\n+        )\r\n+        \r\n+        return self.output_projection(output)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733179740705,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,286 @@\n+from typing import Dict, Any, Optional\r\n+from datetime import datetime\r\n+import pandas as pd\r\n+import torch\r\n+from torch import nn, Tensor\r\n+import math\r\n+\r\n+from data_loading.types.interval_types import TimeInterval\r\n+from .base_resolution_transformer import BaseResolutionTransformer\r\n+from models.registry.factory import ModelFactory\r\n+from models.registry.model_types import ModelType\r\n+from models.components.layers import EncoderLayer, DecoderLayer\r\n+\r\n+@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\n+class MonthlyTransformer(BaseResolutionTransformer):\r\n+    \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n+\r\n+    def __init__(self, config: Dict[str, Any]):\r\n+        # Validate resolution\r\n+        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n+            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n+        \r\n+        super().__init__(config)\r\n+        \r\n+        # Monthly-specific configurations\r\n+        self.seasonal_features = self.d_model // 2\r\n+        self.yearly_features = self.d_model // 2\r\n+        \r\n+        # Setup specialized components\r\n+        self._setup_seasonal_components()\r\n+        self._setup_yearly_components()\r\n+        self._setup_trend_components()\r\n+\r\n+    def _setup_seasonal_components(self) -> None:\r\n+        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n+        # Seasonal embeddings\r\n+        self.season_embedding = nn.Embedding(4, self.d_model)\r\n+        self.month_embedding = nn.Embedding(12, self.d_model)\r\n+        \r\n+        # Seasonal pattern recognition\r\n+        self.seasonal_layer = nn.Sequential(\r\n+            nn.Linear(self.d_model, self.seasonal_features),\r\n+            nn.LayerNorm(self.seasonal_features),\r\n+            nn.GELU(),\r\n+            nn.Linear(self.seasonal_features, self.d_model),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+        \r\n+        # Seasonal attention\r\n+        self.seasonal_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+\r\n+    def _setup_yearly_components(self) -> None:\r\n+        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n+        # Yearly cycle embedding\r\n+        self.yearly_embedding = nn.Parameter(\r\n+            torch.randn(12, self.d_model)  # One embedding per month\r\n+        )\r\n+        \r\n+        # Yearly pattern recognition\r\n+        self.yearly_layer = nn.Sequential(\r\n+            nn.Linear(self.d_model, self.yearly_features),\r\n+            nn.LayerNorm(self.yearly_features),\r\n+            nn.GELU(),\r\n+            nn.Linear(self.yearly_features, self.d_model),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+        \r\n+        # Year-over-year attention\r\n+        self.yearly_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+\r\n+    def _setup_trend_components(self) -> None:\r\n+        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n+        # Long-term trend analysis\r\n+        self.trend_lstm = nn.LSTM(\r\n+            input_size=self.d_model,\r\n+            hidden_size=self.d_model,\r\n+            num_layers=2,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+        \r\n+        # Trend attention mechanism\r\n+        self.trend_attention = nn.MultiheadAttention(\r\n+            embed_dim=self.d_model,\r\n+            num_heads=self.n_heads,\r\n+            dropout=self.dropout,\r\n+            batch_first=True\r\n+        )\r\n+        \r\n+        # Deseasonalization layer\r\n+        self.deseasonalization = nn.Sequential(\r\n+            nn.Linear(self.d_model * 2, self.d_model),\r\n+            nn.LayerNorm(self.d_model),\r\n+            nn.GELU(),\r\n+            nn.Dropout(self.dropout)\r\n+        )\r\n+\r\n+    def _create_encoder_layers(self) -> nn.ModuleList:\r\n+        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n+        return nn.ModuleList([\r\n+            EncoderLayer(\r\n+                d_model=self.d_model,\r\n+                n_heads=self.n_heads,\r\n+                d_ff=self.d_ff,\r\n+                dropout=self.dropout,\r\n+                attention_type=\"standard\",\r\n+                activation=\"gelu\"\r\n+            ) for _ in range(self.n_encoder_layers)\r\n+        ])\r\n+\r\n+    def _create_decoder_layers(self) -> nn.ModuleList:\r\n+        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n+        return nn.ModuleList([\r\n+            DecoderLayer(\r\n+                d_model=self.d_model,\r\n+                n_heads=self.n_heads,\r\n+                d_ff=self.d_ff,\r\n+                dropout=self.dropout,\r\n+                attention_type=\"standard\",\r\n+                activation=\"gelu\"\r\n+            ) for _ in range(self.n_decoder_layers)\r\n+        ])\r\n+\r\n+    def _extract_seasonal_patterns(\r\n+        self,\r\n+        x: Tensor,\r\n+        timestamps: torch.Tensor\r\n+    ) -> Tensor:\r\n+        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n+        # Convert tensor timestamps to pandas datetime\r\n+        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n+        \r\n+        # Get seasonal embeddings\r\n+        season_idx = torch.tensor((dates.month.values - 1) // 3, device=timestamps.device)\r\n+        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n+        \r\n+        seasonal_emb = self.season_embedding(season_idx)\r\n+        month_emb = self.month_embedding(month_idx)\r\n+        \r\n+        # Combine embeddings\r\n+        combined_emb = seasonal_emb + month_emb\r\n+        \r\n+        # Extract seasonal patterns\r\n+        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n+        \r\n+        # Apply seasonal attention\r\n+        seasonal_attn, _ = self.seasonal_attention(\r\n+            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n+        )\r\n+        \r\n+        return seasonal_attn\r\n+\r\n+    def _extract_yearly_patterns(\r\n+        self,\r\n+        x: Tensor,\r\n+        timestamps: Tensor\r\n+    ) -> Tensor:\r\n+        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n+        batch_size, seq_len = x.shape[:2]\r\n+        \r\n+        # Convert tensor timestamps to pandas datetime\r\n+        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n+        \r\n+        # Get yearly embeddings for each timestamp\r\n+        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n+        yearly_emb = self.yearly_embedding[month_idx]\r\n+        \r\n+        # Extract yearly patterns\r\n+        yearly_patterns = self.yearly_layer(yearly_emb)\r\n+        \r\n+        # Apply year-over-year attention\r\n+        yearly_attn, _ = self.yearly_attention(\r\n+            yearly_patterns, yearly_patterns, yearly_patterns\r\n+        )\r\n+        \r\n+        return yearly_attn\r\n+\r\n+    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n+        \"\"\"Analyze long-term trends.\"\"\"\r\n+        # Apply LSTM for trend analysis\r\n+        trend_output, _ = self.trend_lstm(x)\r\n+        \r\n+        # Apply trend attention\r\n+        trend_attn, _ = self.trend_attention(\r\n+            trend_output, trend_output, trend_output\r\n+        )\r\n+        \r\n+        return trend_attn\r\n+\r\n+    def encode(\r\n+        self,\r\n+        src: Tensor,\r\n+        src_mask: Optional[Tensor] = None,\r\n+        src_key_padding_mask: Optional[Tensor] = None,\r\n+        timestamps: Optional[Tensor] = None\r\n+    ) -> Tensor:\r\n+        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n+        # Standard embedding\r\n+        src = self.encoder_embedding(src)\r\n+        \r\n+        if timestamps is not None:\r\n+            # Extract patterns\r\n+            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n+            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n+            trend = self._analyze_trend(src)\r\n+            \r\n+            # Combine patterns\r\n+            src = src + seasonal_patterns + yearly_patterns + trend\r\n+            \r\n+            # Deseasonalize for trend analysis\r\n+            deseasonalized = self.deseasonalization(\r\n+                torch.cat([src, trend], dim=-1)\r\n+            )\r\n+            src = src + deseasonalized\r\n+        \r\n+        # Pass through encoder layers\r\n+        for layer in self.encoder_layers:\r\n+            src = layer(\r\n+                src,\r\n+                src_mask=src_mask,\r\n+                src_key_padding_mask=src_key_padding_mask\r\n+            )\r\n+        return src\r\n+\r\n+    def _adjust_attention_for_resolution(\r\n+        self,\r\n+        attention_weights: Tensor,\r\n+        resolution_minutes: int\r\n+    ) -> Tensor:\r\n+        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n+        seq_len = attention_weights.size(-1)\r\n+        \r\n+        # Seasonal pattern emphasis\r\n+        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n+        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n+        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n+        \r\n+        # Year transition emphasis\r\n+        is_year_end = (months == 11).float()\r\n+        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n+        \r\n+        return attention_weights\r\n+\r\n+    @classmethod\r\n+    def get_resolution_type(cls) -> TimeInterval:\r\n+        \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n+        return TimeInterval.MONTHLY\r\n+\r\n+    def forward(\r\n+        self,\r\n+        src: Tensor,\r\n+        tgt: Tensor,\r\n+        src_mask: Optional[Tensor] = None,\r\n+        tgt_mask: Optional[Tensor] = None,\r\n+        src_key_padding_mask: Optional[Tensor] = None,\r\n+        tgt_key_padding_mask: Optional[Tensor] = None,\r\n+        timestamps: Optional[Tensor] = None\r\n+    ) -> Tensor:\r\n+        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n+        memory = self.encode(\r\n+            src,\r\n+            src_mask=src_mask,\r\n+            src_key_padding_mask=src_key_padding_mask,\r\n+            timestamps=timestamps\r\n+        )\r\n+        \r\n+        output = self.decode(\r\n+            tgt,\r\n+            memory,\r\n+            tgt_mask=tgt_mask,\r\n+            memory_mask=None,\r\n+            tgt_key_padding_mask=tgt_key_padding_mask,\r\n+            memory_key_padding_mask=src_key_padding_mask\r\n+        )\r\n+        \r\n+        return self.output_projection(output)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1733179872839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,851 +1,33 @@\n from typing import Dict, Any, Optional\r\n-from datetime import datetime\r\n-import pandas as pd\r\n import torch\r\n from torch import nn, Tensor\r\n-import math\r\n+import pandas as pd\r\n \r\n from data_loading.types.interval_types import TimeInterval\r\n from .base_resolution_transformer import BaseResolutionTransformer\r\n-from models.registry.factory import ModelFactory\r\n-from models.registry.model_types import ModelType\r\n from models.components.layers import EncoderLayer, DecoderLayer\r\n \r\n-@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\n class MonthlyTransformer(BaseResolutionTransformer):\r\n     \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n-\r\n+    \r\n     def __init__(self, config: Dict[str, Any]):\r\n-        # Validate resolution\r\n-        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n-            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n-        \r\n         super().__init__(config)\r\n         \r\n         # Monthly-specific configurations\r\n-        self.seasonal_features = self.d_model // 2\r\n-        self.yearly_features = self.d_model // 2\r\n+        self.minutes_per_step = config.get('forecast_resolution_minutes', 43200)  # 30 days default\r\n         \r\n-        # Setup specialized components\r\n-        self._setup_seasonal_components()\r\n-        self._setup_yearly_components()\r\n-        self._setup_trend_components()\r\n-\r\n-    def _setup_seasonal_components(self) -> None:\r\n-        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n-        # Seasonal embeddings\r\n-        self.season_embedding = nn.Embedding(4, self.d_model)\r\n-        self.month_embedding = nn.Embedding(12, self.d_model)\r\n-        \r\n-        # Seasonal pattern recognition\r\n-        self.seasonal_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.seasonal_features),\r\n-            nn.LayerNorm(self.seasonal_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.seasonal_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n+        # Enhanced pattern recognition for monthly data\r\n+        self.monthly_pattern_conv = nn.Conv1d(\r\n+            in_channels=self.d_model,\r\n+            out_channels=self.d_model,\r\n+            kernel_size=12,  # Capture yearly patterns\r\n+            padding=6,\r\n+            groups=self.d_model\r\n         )\r\n-        \r\n-        # Seasonal attention\r\n-        self.seasonal_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n \r\n-    def _setup_yearly_components(self) -> None:\r\n-        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n-        # Yearly cycle embedding\r\n-        self.yearly_embedding = nn.Parameter(\r\n-            torch.randn(12, self.d_model)  # One embedding per month\r\n-        )\r\n-        \r\n-        # Yearly pattern recognition\r\n-        self.yearly_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.yearly_features),\r\n-            nn.LayerNorm(self.yearly_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.yearly_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-        \r\n-        # Year-over-year attention\r\n-        self.yearly_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-\r\n-    def _setup_trend_components(self) -> None:\r\n-        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n-        # Long-term trend analysis\r\n-        self.trend_lstm = nn.LSTM(\r\n-            input_size=self.d_model,\r\n-            hidden_size=self.d_model,\r\n-            num_layers=2,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Trend attention mechanism\r\n-        self.trend_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Deseasonalization layer\r\n-        self.deseasonalization = nn.Sequential(\r\n-            nn.Linear(self.d_model * 2, self.d_model),\r\n-            nn.LayerNorm(self.d_model),\r\n-            nn.GELU(),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-\r\n-    def _create_encoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            EncoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_encoder_layers)\r\n-        ])\r\n-\r\n-    def _create_decoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            DecoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_decoder_layers)\r\n-        ])\r\n-\r\n-    def _extract_seasonal_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: torch.Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n-        # Convert tensor timestamps to pandas datetime\r\n-        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n-        \r\n-        # Get seasonal embeddings\r\n-        season_idx = torch.tensor((dates.month.values - 1) // 3, device=timestamps.device)\r\n-        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n-        \r\n-        seasonal_emb = self.season_embedding(season_idx)\r\n-        month_emb = self.month_embedding(month_idx)\r\n-        \r\n-        # Combine embeddings\r\n-        combined_emb = seasonal_emb + month_emb\r\n-        \r\n-        # Extract seasonal patterns\r\n-        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n-        \r\n-        # Apply seasonal attention\r\n-        seasonal_attn, _ = self.seasonal_attention(\r\n-            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n-        )\r\n-        \r\n-        return seasonal_attn\r\n-\r\n-    def _extract_yearly_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n-        batch_size, seq_len = x.shape[:2]\r\n-        \r\n-        # Convert tensor timestamps to pandas datetime\r\n-        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n-        \r\n-        # Get yearly embeddings for each timestamp\r\n-        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n-        yearly_emb = self.yearly_embedding[month_idx]\r\n-        \r\n-        # Extract yearly patterns\r\n-        yearly_patterns = self.yearly_layer(yearly_emb)\r\n-        \r\n-        # Apply year-over-year attention\r\n-        yearly_attn, _ = self.yearly_attention(\r\n-            yearly_patterns, yearly_patterns, yearly_patterns\r\n-        )\r\n-        \r\n-        return yearly_attn\r\n-\r\n-    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n-        \"\"\"Analyze long-term trends.\"\"\"\r\n-        # Apply LSTM for trend analysis\r\n-        trend_output, _ = self.trend_lstm(x)\r\n-        \r\n-        # Apply trend attention\r\n-        trend_attn, _ = self.trend_attention(\r\n-            trend_output, trend_output, trend_output\r\n-        )\r\n-        \r\n-        return trend_attn\r\n-\r\n-    def encode(\r\n-        self,\r\n-        src: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n-        # Standard embedding\r\n-        src = self.encoder_embedding(src)\r\n-        \r\n-        if timestamps is not None:\r\n-            # Extract patterns\r\n-            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n-            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n-            trend = self._analyze_trend(src)\r\n-            \r\n-            # Combine patterns\r\n-            src = src + seasonal_patterns + yearly_patterns + trend\r\n-            \r\n-            # Deseasonalize for trend analysis\r\n-            deseasonalized = self.deseasonalization(\r\n-                torch.cat([src, trend], dim=-1)\r\n-            )\r\n-            src = src + deseasonalized\r\n-        \r\n-        # Pass through encoder layers\r\n-        for layer in self.encoder_layers:\r\n-            src = layer(\r\n-                src,\r\n-                src_mask=src_mask,\r\n-                src_key_padding_mask=src_key_padding_mask\r\n-            )\r\n-        return src\r\n-\r\n-    def _adjust_attention_for_resolution(\r\n-        self,\r\n-        attention_weights: Tensor,\r\n-        resolution_minutes: int\r\n-    ) -> Tensor:\r\n-        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n-        seq_len = attention_weights.size(-1)\r\n-        \r\n-        # Seasonal pattern emphasis\r\n-        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n-        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n-        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        # Year transition emphasis\r\n-        is_year_end = (months == 11).float()\r\n-        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        return attention_weights\r\n-\r\n     @classmethod\r\n     def get_resolution_type(cls) -> TimeInterval:\r\n         \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n         return TimeInterval.MONTHLY\r\n \r\n-    def forward(\r\n-        self,\r\n-        src: Tensor,\r\n-        tgt: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        tgt_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        tgt_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n-        memory = self.encode(\r\n-            src,\r\n-            src_mask=src_mask,\r\n-            src_key_padding_mask=src_key_padding_mask,\r\n-            timestamps=timestamps\r\n-        )\r\n-        \r\n-        output = self.decode(\r\n-            tgt,\r\n-            memory,\r\n-            tgt_mask=tgt_mask,\r\n-            memory_mask=None,\r\n-            tgt_key_padding_mask=tgt_key_padding_mask,\r\n-            memory_key_padding_mask=src_key_padding_mask\r\n-        )\r\n-        \r\n-        return self.output_projection(output)\n-from typing import Dict, Any, Optional\r\n-from datetime import datetime\r\n-import pandas as pd\r\n-import torch\r\n-from torch import nn, Tensor\r\n-import math\r\n-\r\n-from data_loading.types.interval_types import TimeInterval\r\n-from .base_resolution_transformer import BaseResolutionTransformer\r\n-from ....registry.factory import ModelFactory\r\n-from ....registry.model_types import ModelType\r\n-from ....components.layers import EncoderLayer, DecoderLayer\r\n-\r\n-@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\n-class MonthlyTransformer(BaseResolutionTransformer):\r\n-    \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n-\r\n-    def __init__(self, config: Dict[str, Any]):\r\n-        # Validate resolution\r\n-        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n-            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n-        \r\n-        super().__init__(config)\r\n-        \r\n-        # Monthly-specific configurations\r\n-        self.seasonal_features = self.d_model // 2\r\n-        self.yearly_features = self.d_model // 2\r\n-        \r\n-        # Setup specialized components\r\n-        self._setup_seasonal_components()\r\n-        self._setup_yearly_components()\r\n-        self._setup_trend_components()\r\n-\r\n-    def _setup_seasonal_components(self) -> None:\r\n-        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n-        # Seasonal embeddings\r\n-        self.season_embedding = nn.Embedding(4, self.d_model)\r\n-        self.month_embedding = nn.Embedding(12, self.d_model)\r\n-        \r\n-        # Seasonal pattern recognition\r\n-        self.seasonal_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.seasonal_features),\r\n-            nn.LayerNorm(self.seasonal_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.seasonal_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-        \r\n-        # Seasonal attention\r\n-        self.seasonal_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-\r\n-    def _setup_yearly_components(self) -> None:\r\n-        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n-        # Yearly cycle embedding\r\n-        self.yearly_embedding = nn.Parameter(\r\n-            torch.randn(12, self.d_model)  # One embedding per month\r\n-        )\r\n-        \r\n-        # Yearly pattern recognition\r\n-        self.yearly_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.yearly_features),\r\n-            nn.LayerNorm(self.yearly_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.yearly_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-        \r\n-        # Year-over-year attention\r\n-        self.yearly_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-\r\n-    def _setup_trend_components(self) -> None:\r\n-        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n-        # Long-term trend analysis\r\n-        self.trend_lstm = nn.LSTM(\r\n-            input_size=self.d_model,\r\n-            hidden_size=self.d_model,\r\n-            num_layers=2,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Trend attention mechanism\r\n-        self.trend_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Deseasonalization layer\r\n-        self.deseasonalization = nn.Sequential(\r\n-            nn.Linear(self.d_model * 2, self.d_model),\r\n-            nn.LayerNorm(self.d_model),\r\n-            nn.GELU(),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-\r\n-    def _create_encoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            EncoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_encoder_layers)\r\n-        ])\r\n-\r\n-    def _create_decoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            DecoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_decoder_layers)\r\n-        ])\r\n-\r\n-    def _extract_seasonal_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: torch.Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n-        # Convert tensor timestamps to pandas datetime\r\n-        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n-        \r\n-        # Get seasonal embeddings\r\n-        season_idx = torch.tensor((dates.month.values - 1) // 3, device=timestamps.device)\r\n-        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n-        \r\n-        seasonal_emb = self.season_embedding(season_idx)\r\n-        month_emb = self.month_embedding(month_idx)\r\n-        \r\n-        # Combine embeddings\r\n-        combined_emb = seasonal_emb + month_emb\r\n-        \r\n-        # Extract seasonal patterns\r\n-        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n-        \r\n-        # Apply seasonal attention\r\n-        seasonal_attn, _ = self.seasonal_attention(\r\n-            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n-        )\r\n-        \r\n-        return seasonal_attn\r\n-\r\n-    def _extract_yearly_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n-        batch_size, seq_len = x.shape[:2]\r\n-        \r\n-        # Convert tensor timestamps to pandas datetime\r\n-        dates = pd.to_datetime(timestamps.cpu().numpy(), unit='s')\r\n-        \r\n-        # Get yearly embeddings for each timestamp\r\n-        month_idx = torch.tensor(dates.month.values - 1, device=timestamps.device)\r\n-        yearly_emb = self.yearly_embedding[month_idx]\r\n-        \r\n-        # Extract yearly patterns\r\n-        yearly_patterns = self.yearly_layer(yearly_emb)\r\n-        \r\n-        # Apply year-over-year attention\r\n-        yearly_attn, _ = self.yearly_attention(\r\n-            yearly_patterns, yearly_patterns, yearly_patterns\r\n-        )\r\n-        \r\n-        return yearly_attn\r\n-\r\n-    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n-        \"\"\"Analyze long-term trends.\"\"\"\r\n-        # Apply LSTM for trend analysis\r\n-        trend_output, _ = self.trend_lstm(x)\r\n-        \r\n-        # Apply trend attention\r\n-        trend_attn, _ = self.trend_attention(\r\n-            trend_output, trend_output, trend_output\r\n-        )\r\n-        \r\n-        return trend_attn\r\n-\r\n-    def encode(\r\n-        self,\r\n-        src: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n-        # Standard embedding\r\n-        src = self.encoder_embedding(src)\r\n-        \r\n-        if timestamps is not None:\r\n-            # Extract patterns\r\n-            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n-            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n-            trend = self._analyze_trend(src)\r\n-            \r\n-            # Combine patterns\r\n-            src = src + seasonal_patterns + yearly_patterns + trend\r\n-            \r\n-            # Deseasonalize for trend analysis\r\n-            deseasonalized = self.deseasonalization(\r\n-                torch.cat([src, trend], dim=-1)\r\n-            )\r\n-            src = src + deseasonalized\r\n-        \r\n-        # Pass through encoder layers\r\n-        for layer in self.encoder_layers:\r\n-            src = layer(\r\n-                src,\r\n-                src_mask=src_mask,\r\n-                src_key_padding_mask=src_key_padding_mask\r\n-            )\r\n-        return src\r\n-\r\n-    def _adjust_attention_for_resolution(\r\n-        self,\r\n-        attention_weights: Tensor,\r\n-        resolution_minutes: int\r\n-    ) -> Tensor:\r\n-        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n-        seq_len = attention_weights.size(-1)\r\n-        \r\n-        # Seasonal pattern emphasis\r\n-        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n-        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n-        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        # Year transition emphasis\r\n-        is_year_end = (months == 11).float()\r\n-        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        return attention_weights\r\n-\r\n-    @classmethod\r\n-    def get_resolution_type(cls) -> TimeInterval:\r\n-        \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n-        return TimeInterval.MONTHLY\r\n-\r\n-    def forward(\r\n-        self,\r\n-        src: Tensor,\r\n-        tgt: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        tgt_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        tgt_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n-        memory = self.encode(\r\n-            src,\r\n-            src_mask=src_mask,\r\n-            src_key_padding_mask=src_key_padding_mask,\r\n-            timestamps=timestamps\r\n-        )\r\n-        \r\n-        output = self.decode(\r\n-            tgt,\r\n-            memory,\r\n-            tgt_mask=tgt_mask,\r\n-            memory_mask=None,\r\n-            tgt_key_padding_mask=tgt_key_padding_mask,\r\n-            memory_key_padding_mask=src_key_padding_mask\r\n-        )\r\n-        \r\n-        return self.output_projection(output)\n-# models/architectures/transformers/resolution_specific/monthly_transformer.py\r\n-from typing import Dict, Any, Optional\r\n-import torch\r\n-from torch import nn, Tensor\r\n-import math\r\n-\r\n-from data_loading.types.interval_types import TimeInterval\r\n-from .base_resolution_transformer import BaseResolutionTransformer\r\n-from ....registry.factory import ModelFactory\r\n-from ....registry.model_types import ModelType\r\n-from ....components.layers import EncoderLayer, DecoderLayer\r\n-\r\n-@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\n-class MonthlyTransformer(BaseResolutionTransformer):\r\n-    \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n-\r\n-    def __init__(self, config: Dict[str, Any]):\r\n-        # Validate resolution\r\n-        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n-            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n-        \r\n-        super().__init__(config)\r\n-        \r\n-        # Monthly-specific configurations\r\n-        self.seasonal_features = self.d_model // 2\r\n-        self.yearly_features = self.d_model // 2\r\n-        \r\n-        # Setup specialized components\r\n-        self._setup_seasonal_components()\r\n-        self._setup_yearly_components()\r\n-        self._setup_trend_components()\r\n-\r\n-    def _setup_seasonal_components(self) -> None:\r\n-        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n-        # Seasonal embeddings\r\n-        self.season_embedding = nn.Embedding(4, self.d_model)\r\n-        self.month_embedding = nn.Embedding(12, self.d_model)\r\n-        \r\n-        # Seasonal pattern recognition\r\n-        self.seasonal_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.seasonal_features),\r\n-            nn.LayerNorm(self.seasonal_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.seasonal_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-        \r\n-        # Seasonal attention\r\n-        self.seasonal_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-\r\n-    def _setup_yearly_components(self) -> None:\r\n-        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n-        # Yearly cycle embedding\r\n-        self.yearly_embedding = nn.Parameter(\r\n-            torch.randn(12, self.d_model)  # One embedding per month\r\n-        )\r\n-        \r\n-        # Yearly pattern recognition\r\n-        self.yearly_layer = nn.Sequential(\r\n-            nn.Linear(self.d_model, self.yearly_features),\r\n-            nn.LayerNorm(self.yearly_features),\r\n-            nn.GELU(),\r\n-            nn.Linear(self.yearly_features, self.d_model),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-        \r\n-        # Year-over-year attention\r\n-        self.yearly_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-\r\n-    def _setup_trend_components(self) -> None:\r\n-        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n-        # Long-term trend analysis\r\n-        self.trend_lstm = nn.LSTM(\r\n-            input_size=self.d_model,\r\n-            hidden_size=self.d_model,\r\n-            num_layers=2,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Trend attention mechanism\r\n-        self.trend_attention = nn.MultiheadAttention(\r\n-            embed_dim=self.d_model,\r\n-            num_heads=self.n_heads,\r\n-            dropout=self.dropout,\r\n-            batch_first=True\r\n-        )\r\n-        \r\n-        # Deseasonalization layer\r\n-        self.deseasonalization = nn.Sequential(\r\n-            nn.Linear(self.d_model * 2, self.d_model),\r\n-            nn.LayerNorm(self.d_model),\r\n-            nn.GELU(),\r\n-            nn.Dropout(self.dropout)\r\n-        )\r\n-\r\n-    def _create_encoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            EncoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_encoder_layers)\r\n-        ])\r\n-\r\n-    def _create_decoder_layers(self) -> nn.ModuleList:\r\n-        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n-        return nn.ModuleList([\r\n-            DecoderLayer(\r\n-                d_model=self.d_model,\r\n-                n_heads=self.n_heads,\r\n-                d_ff=self.d_ff,\r\n-                dropout=self.dropout,\r\n-                attention_type=\"standard\",\r\n-                activation=\"gelu\"\r\n-            ) for _ in range(self.n_decoder_layers)\r\n-        ])\r\n-\r\n-    def _extract_seasonal_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n-        # Get seasonal embeddings\r\n-        season_idx = (timestamps.month - 1) // 3\r\n-        month_idx = timestamps.month - 1\r\n-        \r\n-        seasonal_emb = self.season_embedding(season_idx)\r\n-        month_emb = self.month_embedding(month_idx)\r\n-        \r\n-        # Combine embeddings\r\n-        combined_emb = seasonal_emb + month_emb\r\n-        \r\n-        # Extract seasonal patterns\r\n-        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n-        \r\n-        # Apply seasonal attention\r\n-        seasonal_attn, _ = self.seasonal_attention(\r\n-            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n-        )\r\n-        \r\n-        return seasonal_attn\r\n-\r\n-    def _extract_yearly_patterns(\r\n-        self,\r\n-        x: Tensor,\r\n-        timestamps: Tensor\r\n-    ) -> Tensor:\r\n-        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n-        batch_size, seq_len = x.shape[:2]\r\n-        \r\n-        # Get yearly embeddings for each timestamp\r\n-        month_idx = timestamps.month - 1\r\n-        yearly_emb = self.yearly_embedding[month_idx]\r\n-        \r\n-        # Extract yearly patterns\r\n-        yearly_patterns = self.yearly_layer(yearly_emb)\r\n-        \r\n-        # Apply year-over-year attention\r\n-        yearly_attn, _ = self.yearly_attention(\r\n-            yearly_patterns, yearly_patterns, yearly_patterns\r\n-        )\r\n-        \r\n-        return yearly_attn\r\n-\r\n-    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n-        \"\"\"Analyze long-term trends.\"\"\"\r\n-        # Apply LSTM for trend analysis\r\n-        trend_output, _ = self.trend_lstm(x)\r\n-        \r\n-        # Apply trend attention\r\n-        trend_attn, _ = self.trend_attention(\r\n-            trend_output, trend_output, trend_output\r\n-        )\r\n-        \r\n-        return trend_attn\r\n-\r\n-    def encode(\r\n-        self,\r\n-        src: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n-        # Standard embedding\r\n-        src = self.encoder_embedding(src)\r\n-        \r\n-        if timestamps is not None:\r\n-            # Extract patterns\r\n-            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n-            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n-            trend = self._analyze_trend(src)\r\n-            \r\n-            # Combine patterns\r\n-            src = src + seasonal_patterns + yearly_patterns + trend\r\n-            \r\n-            # Deseasonalize for trend analysis\r\n-            deseasonalized = self.deseasonalization(\r\n-                torch.cat([src, trend], dim=-1)\r\n-            )\r\n-            src = src + deseasonalized\r\n-        \r\n-        # Pass through encoder layers\r\n-        for layer in self.encoder_layers:\r\n-            src = layer(\r\n-                src,\r\n-                src_mask=src_mask,\r\n-                src_key_padding_mask=src_key_padding_mask\r\n-            )\r\n-        return src\r\n-\r\n-    def _adjust_attention_for_resolution(\r\n-        self,\r\n-        attention_weights: Tensor,\r\n-        resolution_minutes: int\r\n-    ) -> Tensor:\r\n-        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n-        seq_len = attention_weights.size(-1)\r\n-        \r\n-        # Seasonal pattern emphasis\r\n-        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n-        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n-        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        # Year transition emphasis\r\n-        is_year_end = (months == 11).float()\r\n-        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n-        \r\n-        return attention_weights\r\n-\r\n-    @classmethod\r\n-    def get_resolution_type(cls) -> TimeInterval:\r\n-        \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n-        return TimeInterval.MONTHLY\r\n-\r\n-    def forward(\r\n-        self,\r\n-        src: Tensor,\r\n-        tgt: Tensor,\r\n-        src_mask: Optional[Tensor] = None,\r\n-        tgt_mask: Optional[Tensor] = None,\r\n-        src_key_padding_mask: Optional[Tensor] = None,\r\n-        tgt_key_padding_mask: Optional[Tensor] = None,\r\n-        timestamps: Optional[Tensor] = None\r\n-    ) -> Tensor:\r\n-        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n-        memory = self.encode(\r\n-            src,\r\n-            src_mask=src_mask,\r\n-            src_key_padding_mask=src_key_padding_mask,\r\n-            timestamps=timestamps\r\n-        )\r\n-        \r\n\\ No newline at end of file\n-        output = self.decode(\r\n-            tgt,\r\n-            memory,\r\n-            tgt_mask=tgt_mask,\r\n-            memory_mask=None,\r\n-            tgt_key_padding_mask=tgt_key_padding_mask,\r\n-            memory_key_padding_mask=src_key_padding_mask\r\n-        )\r\n-        \r\n-        return self.output_projection(output)\n+    # ...rest of implementation similar to SubhourlyTransformer...\n\\ No newline at end of file\n"
                }
            ],
            "date": 1733172086006,
            "name": "Commit-0",
            "content": "# models/architectures/transformers/resolution_specific/monthly_transformer.py\r\nfrom typing import Dict, Any, Optional\r\nimport torch\r\nfrom torch import nn, Tensor\r\nimport math\r\n\r\nfrom ....data_loading.base.interval_types import TimeInterval\r\nfrom .base_resolution_transformer import BaseResolutionTransformer\r\nfrom ....registry.factory import ModelFactory\r\nfrom ....registry.model_types import ModelType\r\nfrom ....components.layers import EncoderLayer, DecoderLayer\r\n\r\n@ModelFactory.register(ModelType.MONTHLY_TRANSFORMER)\r\nclass MonthlyTransformer(BaseResolutionTransformer):\r\n    \"\"\"Transformer optimized for monthly predictions.\"\"\"\r\n\r\n    def __init__(self, config: Dict[str, Any]):\r\n        # Validate resolution\r\n        if config.get('forecast_resolution_minutes', 43200) < 43200:  # 30 days\r\n            raise ValueError(\"MonthlyTransformer is designed for monthly resolution (≥43200 minutes)\")\r\n        \r\n        super().__init__(config)\r\n        \r\n        # Monthly-specific configurations\r\n        self.seasonal_features = self.d_model // 2\r\n        self.yearly_features = self.d_model // 2\r\n        \r\n        # Setup specialized components\r\n        self._setup_seasonal_components()\r\n        self._setup_yearly_components()\r\n        self._setup_trend_components()\r\n\r\n    def _setup_seasonal_components(self) -> None:\r\n        \"\"\"Setup components for seasonal pattern recognition.\"\"\"\r\n        # Seasonal embeddings\r\n        self.season_embedding = nn.Embedding(4, self.d_model)\r\n        self.month_embedding = nn.Embedding(12, self.d_model)\r\n        \r\n        # Seasonal pattern recognition\r\n        self.seasonal_layer = nn.Sequential(\r\n            nn.Linear(self.d_model, self.seasonal_features),\r\n            nn.LayerNorm(self.seasonal_features),\r\n            nn.GELU(),\r\n            nn.Linear(self.seasonal_features, self.d_model),\r\n            nn.Dropout(self.dropout)\r\n        )\r\n        \r\n        # Seasonal attention\r\n        self.seasonal_attention = nn.MultiheadAttention(\r\n            embed_dim=self.d_model,\r\n            num_heads=self.n_heads,\r\n            dropout=self.dropout,\r\n            batch_first=True\r\n        )\r\n\r\n    def _setup_yearly_components(self) -> None:\r\n        \"\"\"Setup components for yearly pattern recognition.\"\"\"\r\n        # Yearly cycle embedding\r\n        self.yearly_embedding = nn.Parameter(\r\n            torch.randn(12, self.d_model)  # One embedding per month\r\n        )\r\n        \r\n        # Yearly pattern recognition\r\n        self.yearly_layer = nn.Sequential(\r\n            nn.Linear(self.d_model, self.yearly_features),\r\n            nn.LayerNorm(self.yearly_features),\r\n            nn.GELU(),\r\n            nn.Linear(self.yearly_features, self.d_model),\r\n            nn.Dropout(self.dropout)\r\n        )\r\n        \r\n        # Year-over-year attention\r\n        self.yearly_attention = nn.MultiheadAttention(\r\n            embed_dim=self.d_model,\r\n            num_heads=self.n_heads,\r\n            dropout=self.dropout,\r\n            batch_first=True\r\n        )\r\n\r\n    def _setup_trend_components(self) -> None:\r\n        \"\"\"Setup components for long-term trend analysis.\"\"\"\r\n        # Long-term trend analysis\r\n        self.trend_lstm = nn.LSTM(\r\n            input_size=self.d_model,\r\n            hidden_size=self.d_model,\r\n            num_layers=2,\r\n            dropout=self.dropout,\r\n            batch_first=True\r\n        )\r\n        \r\n        # Trend attention mechanism\r\n        self.trend_attention = nn.MultiheadAttention(\r\n            embed_dim=self.d_model,\r\n            num_heads=self.n_heads,\r\n            dropout=self.dropout,\r\n            batch_first=True\r\n        )\r\n        \r\n        # Deseasonalization layer\r\n        self.deseasonalization = nn.Sequential(\r\n            nn.Linear(self.d_model * 2, self.d_model),\r\n            nn.LayerNorm(self.d_model),\r\n            nn.GELU(),\r\n            nn.Dropout(self.dropout)\r\n        )\r\n\r\n    def _create_encoder_layers(self) -> nn.ModuleList:\r\n        \"\"\"Create encoder layers optimized for monthly patterns.\"\"\"\r\n        return nn.ModuleList([\r\n            EncoderLayer(\r\n                d_model=self.d_model,\r\n                n_heads=self.n_heads,\r\n                d_ff=self.d_ff,\r\n                dropout=self.dropout,\r\n                attention_type=\"standard\",\r\n                activation=\"gelu\"\r\n            ) for _ in range(self.n_encoder_layers)\r\n        ])\r\n\r\n    def _create_decoder_layers(self) -> nn.ModuleList:\r\n        \"\"\"Create decoder layers optimized for monthly patterns.\"\"\"\r\n        return nn.ModuleList([\r\n            DecoderLayer(\r\n                d_model=self.d_model,\r\n                n_heads=self.n_heads,\r\n                d_ff=self.d_ff,\r\n                dropout=self.dropout,\r\n                attention_type=\"standard\",\r\n                activation=\"gelu\"\r\n            ) for _ in range(self.n_decoder_layers)\r\n        ])\r\n\r\n    def _extract_seasonal_patterns(\r\n        self,\r\n        x: Tensor,\r\n        timestamps: Tensor\r\n    ) -> Tensor:\r\n        \"\"\"Extract and enhance seasonal patterns.\"\"\"\r\n        # Get seasonal embeddings\r\n        season_idx = (timestamps.month - 1) // 3\r\n        month_idx = timestamps.month - 1\r\n        \r\n        seasonal_emb = self.season_embedding(season_idx)\r\n        month_emb = self.month_embedding(month_idx)\r\n        \r\n        # Combine embeddings\r\n        combined_emb = seasonal_emb + month_emb\r\n        \r\n        # Extract seasonal patterns\r\n        seasonal_patterns = self.seasonal_layer(combined_emb)\r\n        \r\n        # Apply seasonal attention\r\n        seasonal_attn, _ = self.seasonal_attention(\r\n            seasonal_patterns, seasonal_patterns, seasonal_patterns\r\n        )\r\n        \r\n        return seasonal_attn\r\n\r\n    def _extract_yearly_patterns(\r\n        self,\r\n        x: Tensor,\r\n        timestamps: Tensor\r\n    ) -> Tensor:\r\n        \"\"\"Extract and enhance yearly patterns.\"\"\"\r\n        batch_size, seq_len = x.shape[:2]\r\n        \r\n        # Get yearly embeddings for each timestamp\r\n        month_idx = timestamps.month - 1\r\n        yearly_emb = self.yearly_embedding[month_idx]\r\n        \r\n        # Extract yearly patterns\r\n        yearly_patterns = self.yearly_layer(yearly_emb)\r\n        \r\n        # Apply year-over-year attention\r\n        yearly_attn, _ = self.yearly_attention(\r\n            yearly_patterns, yearly_patterns, yearly_patterns\r\n        )\r\n        \r\n        return yearly_attn\r\n\r\n    def _analyze_trend(self, x: Tensor) -> Tensor:\r\n        \"\"\"Analyze long-term trends.\"\"\"\r\n        # Apply LSTM for trend analysis\r\n        trend_output, _ = self.trend_lstm(x)\r\n        \r\n        # Apply trend attention\r\n        trend_attn, _ = self.trend_attention(\r\n            trend_output, trend_output, trend_output\r\n        )\r\n        \r\n        return trend_attn\r\n\r\n    def encode(\r\n        self,\r\n        src: Tensor,\r\n        src_mask: Optional[Tensor] = None,\r\n        src_key_padding_mask: Optional[Tensor] = None,\r\n        timestamps: Optional[Tensor] = None\r\n    ) -> Tensor:\r\n        \"\"\"Enhanced encoding with monthly pattern recognition.\"\"\"\r\n        # Standard embedding\r\n        src = self.encoder_embedding(src)\r\n        \r\n        if timestamps is not None:\r\n            # Extract patterns\r\n            seasonal_patterns = self._extract_seasonal_patterns(src, timestamps)\r\n            yearly_patterns = self._extract_yearly_patterns(src, timestamps)\r\n            trend = self._analyze_trend(src)\r\n            \r\n            # Combine patterns\r\n            src = src + seasonal_patterns + yearly_patterns + trend\r\n            \r\n            # Deseasonalize for trend analysis\r\n            deseasonalized = self.deseasonalization(\r\n                torch.cat([src, trend], dim=-1)\r\n            )\r\n            src = src + deseasonalized\r\n        \r\n        # Pass through encoder layers\r\n        for layer in self.encoder_layers:\r\n            src = layer(\r\n                src,\r\n                src_mask=src_mask,\r\n                src_key_padding_mask=src_key_padding_mask\r\n            )\r\n        return src\r\n\r\n    def _adjust_attention_for_resolution(\r\n        self,\r\n        attention_weights: Tensor,\r\n        resolution_minutes: int\r\n    ) -> Tensor:\r\n        \"\"\"Adjust attention weights for monthly patterns.\"\"\"\r\n        seq_len = attention_weights.size(-1)\r\n        \r\n        # Seasonal pattern emphasis\r\n        months = torch.arange(seq_len, device=attention_weights.device) % 12\r\n        seasonal_weights = torch.cos(2 * math.pi * months / 12)\r\n        attention_weights = attention_weights * (1 + 0.3 * seasonal_weights.unsqueeze(0).unsqueeze(0))\r\n        \r\n        # Year transition emphasis\r\n        is_year_end = (months == 11).float()\r\n        attention_weights = attention_weights * (1 + 0.2 * is_year_end.unsqueeze(0).unsqueeze(0))\r\n        \r\n        return attention_weights\r\n\r\n    @classmethod\r\n    def get_resolution_type(cls) -> TimeInterval:\r\n        \"\"\"Get the time interval type for monthly transformer.\"\"\"\r\n        return TimeInterval.MONTHLY\r\n\r\n    def forward(\r\n        self,\r\n        src: Tensor,\r\n        tgt: Tensor,\r\n        src_mask: Optional[Tensor] = None,\r\n        tgt_mask: Optional[Tensor] = None,\r\n        src_key_padding_mask: Optional[Tensor] = None,\r\n        tgt_key_padding_mask: Optional[Tensor] = None,\r\n        timestamps: Optional[Tensor] = None\r\n    ) -> Tensor:\r\n        \"\"\"Forward pass with enhanced monthly pattern recognition.\"\"\"\r\n        memory = self.encode(\r\n            src,\r\n            src_mask=src_mask,\r\n            src_key_padding_mask=src_key_padding_mask,\r\n            timestamps=timestamps\r\n        )\r\n        \r\n        output = self.decode(\r\n            tgt,\r\n            memory,\r\n            tgt_mask=tgt_mask,\r\n            memory_mask=None,\r\n            tgt_key_padding_mask=tgt_key_padding_mask,\r\n            memory_key_padding_mask=src_key_padding_mask\r\n        )\r\n        \r\n        return self.output_projection(output)"
        }
    ]
}